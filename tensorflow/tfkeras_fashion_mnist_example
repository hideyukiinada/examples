#!/usr/bin/env python
"""
A Fashion MNIST example using tf.keras

This is a re-implementation of my Fashion MNIST example code in Tensorflow using tf.keras class (as opposed to pure Keras)
below:
https://github.com/hideyukiinada/ml/blob/master/examples/weight_persistence_mnist_example

__author__ = "Hide Inada"
__copyright__ = "Copyright 2018, Hide Inada"
__license__ = "The MIT License"
__email__ = "hideyuki@gmail.com"
"""

import os
import logging

import tensorflow as tf
import numpy as np
import keras

from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Dense
from tensorflow.python.keras.layers import Conv2D
from tensorflow.python.keras.layers import MaxPool2D
from tensorflow.python.keras.layers import Flatten

log = logging.getLogger(__name__)
logging.basicConfig(level=os.environ.get("LOGLEVEL", "INFO"))  # Change the 2nd arg to INFO to suppress debug logging

EPOCH_SIZE = 2


def example():
    """Train the model and predict.
    """

    # Download fashion mnist data via Keras API
    (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()

    # Change the value from 0<= x <= 255 in UINT8 to 0 <= x <= 1 in float
    x_train = x_train / 255.0
    x_test = x_test / 255.0

    # Reshape data
    x_train = (x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)).astype(np.float32)
    x_test = (x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)).astype(np.float32)

    y_train_one_hot = y_train.reshape(y_train.shape[0], 1)
    y_train_one_hot = keras.utils.to_categorical(y_train_one_hot, 10).astype(np.float32)

    y_test_one_hot = y_test.reshape(y_test.shape[0], 1)
    y_test_one_hot = keras.utils.to_categorical(y_test_one_hot, 10).astype(np.float32)

    # Set up a model
    model = Sequential()
    model.add(Conv2D(filters=8, kernel_size=5, activation="relu"))
    model.add(MaxPool2D(strides=2))

    model.add(Conv2D(filters=16, kernel_size=3, activation="relu"))
    model.add(MaxPool2D(strides=2))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dense(10, activation='softmax'))

    # Note the use of tf.train.AdamOptimizer instead of tf.keras.optimizers.Adam
    optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999)
    model.compile(loss=tf.keras.losses.categorical_crossentropy,
                  optimizer=optimizer, metrics=['accuracy'])

    model.fit(x=x_train, y=y_train_one_hot, epochs=EPOCH_SIZE)

    y_hat_test_one_hot = model.predict(x_test)

    total_size = y_hat_test_one_hot.shape[0]
    y_hat_test_one_hot_int = np.argmax(y_hat_test_one_hot, axis=1)  # to int from one-hot vector

    matched_indices = (y_hat_test_one_hot_int == y_test)
    matched_count = y_test[matched_indices].shape[0]
    log.info(
        "Matched: %d out of Total: %d (%f percent)" % (matched_count, total_size, matched_count * 100 / total_size))


def main():
    """Defines an application's main functionality"""
    example()


if __name__ == "__main__":
    main()

#!/usr/bin/env python
"""
An example code to demo the use of tf.data.Dataset

References on how to use iterator
---------------------------------
https://www.tensorflow.org/guide/datasets

__author__ = "Hide Inada"
__copyright__ = "Copyright 2018, Hide Inada"
__license__ = "The MIT License"
__email__ = "hideyuki@gmail.com"
"""

import os
import logging

import tensorflow as tf
import numpy as np

import keras

log = logging.getLogger(__name__)
logging.basicConfig(level=os.environ.get("LOGLEVEL", "INFO"))  # Change the 2nd arg to INFO to suppress debug logging


def example():
    """An example code.
    """
    tf.reset_default_graph()

    x_data = [1., 2., 3., 4., 5.]
    y_data = [1., 0., 0., 1., 0.]

    # Create a placeholder for data.  This is the same as regular feed_dict mechanism
    ph = tf.placeholder(tf.float32, shape=(None,))   # type & shape

    # Connect placeholder to dataset. This is different from the feed_dict mechanism
    ds = tf.data.Dataset.from_tensor_slices((ph))

    # Transform data
    # Multiply and repeat once.  Note that the count is the total number of occurrences.
    ds2 = ds.map(lambda e: e*2).repeat(2)

    it = ds2.make_initializable_iterator()
    next_op = it.get_next()

    init_op = tf.global_variables_initializer()  # Set up operator to assign all init values to variables

    with tf.Session() as s:
        s.run(init_op)  # Actually assign initial value to variables

        s.run(it.initializer, {ph:x_data})

        while True:
            try:
                next_a_val = s.run(next_op)
                print(next_a_val)

            except tf.errors.OutOfRangeError:
                print("All data in a have been returned by the iterator")
                break

def main():
    """Defines an application's main functionality"""
    example()


if __name__ == "__main__":
    main()

#!/usr/bin/env python
"""
A Fashion MNIST example using TensorFlow.

This is a re-implementation of my Fashion MNIST example code in Tensorflow with support for visualization using
TensorBoard:
https://github.com/hideyukiinada/ml/blob/master/examples/weight_persistence_mnist_example

__author__ = "Hide Inada"
__copyright__ = "Copyright 2018, Hide Inada"
__license__ = "The MIT License"
__email__ = "hideyuki@gmail.com"
"""

import os
import logging

import tensorflow as tf
import numpy as np
from pathlib import Path
import keras

log = logging.getLogger(__name__)
logging.basicConfig(level=os.environ.get("LOGLEVEL", "INFO"))  # Change the 2nd arg to INFO to suppress debug logging

EPOCH_SIZE = 5
BATCH_SIZE = 32

WEIGHT_DIR = "../../weights"
TENSORBOARD_LOG_DIR = "/tmp/examples_tf/log"


def example():
    """An example to train the model using MNIST data and predict.
    """
    tf.reset_default_graph()

    # Download fashion mnist data via Keras API
    (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()

    # Change the value from 0<= x <= 255 in UINT8 to 0 <= x <= 1 in float
    x_train = x_train / 255.0
    x_test = x_test / 255.0

    x_train = (x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)).astype(np.float32)
    x_test = (x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)).astype(np.float32)

    y_train_one_hot = y_train.reshape(y_train.shape[0], 1)
    y_train_one_hot = keras.utils.to_categorical(y_train_one_hot, 10).astype(np.float32)

    x_placeholder = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))
    y_placeholder = tf.placeholder(tf.float32, shape=(None, 10))

    # Set up conv net
    with tf.variable_scope("conv1") as scope:
        weights = tf.get_variable("weights", [5, 5, 1, 8], dtype=tf.float32,
                                  initializer=tf.contrib.layers.xavier_initializer(seed=0))
        bias = tf.get_variable("bias", [8], dtype=tf.float32)
        z = tf.add(tf.nn.conv2d(x_placeholder, weights, strides=[1, 1, 1, 1], padding='SAME'), bias)
        activation = tf.nn.relu(z, name=scope.name)
        # Apply pooling with ksize: batch, h, w, channel
        p1 = tf.nn.max_pool(activation, ksize=(1, 2, 2, 1), strides=[1, 2, 2, 1], padding='VALID')  # to 14x14

    with tf.variable_scope("conv2") as scope:
        weights = tf.get_variable("weights", [3, 3, 8, 16], dtype=tf.float32,
                                  initializer=tf.contrib.layers.xavier_initializer(seed=0))
        bias = tf.get_variable("bias", [16], dtype=tf.float32)
        z = tf.add(tf.nn.conv2d(p1, weights, strides=[1, 1, 1, 1], padding='SAME'), bias)
        activation = tf.nn.relu(z, name=scope.name)
        p2 = tf.nn.max_pool(activation, ksize=(1, 2, 2, 1), strides=[1, 2, 2, 1], padding='VALID')  # to 7x7

    flat = tf.contrib.layers.flatten(p2)
    fc1 = tf.contrib.layers.fully_connected(flat, activation_fn=tf.nn.relu, num_outputs=128)
    fc2 = tf.contrib.layers.fully_connected(fc1, activation_fn=None, num_outputs=10)
    y_hat_softmax = tf.nn.softmax(fc2)  # you can just use fc2 for prediction if you want to further optimize

    # Set up optimizer & cost
    optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999)
    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=fc2, labels=y_placeholder))

    tf.summary.scalar('cost', cost)

    objective = optimizer.minimize(cost)

    init_op = tf.global_variables_initializer()  # Set up operator to assign all init values to variables

    saver = tf.train.Saver()
    merged = tf.summary.merge_all()

    with tf.Session() as s:

        tensorboard_writer = tf.summary.FileWriter(TENSORBOARD_LOG_DIR, s.graph)

        if Path(WEIGHT_DIR).exists():
            try:
                saver.restore(s, str(Path(WEIGHT_DIR) / Path("model.ckpt")))
                log.info("Loaded weight from: %s" % str(Path(WEIGHT_DIR) / Path("model.ckpt")))
            except:
                log.info("Weights could not be loaded. Proceeding.")
        else:
            log.info("Weights not found. Proceeding.")
        s.run(init_op)  # Actually assign initial value to variables

        dataset_size = y_train.shape[0]

        for i in range(EPOCH_SIZE):
            next_k = 0
            loop_count = int(
                dataset_size / BATCH_SIZE)  # for m = 5, batch_size = 2, this results in [0, 1]
            current_batch_size = 0
            batch_id = 0
            for j in range(loop_count):
                current_batch_size = BATCH_SIZE
                k = j * current_batch_size
                next_k = k + current_batch_size

                summary, o, c = s.run([merged, objective, cost],
                                      feed_dict={x_placeholder: x_train[k:next_k],
                                                 y_placeholder: y_train_one_hot[k:next_k]})

                print("Epoch: %d.  Batch: %d Cost:%f, Batch size: %d" % (i, batch_id, c, current_batch_size))
                tensorboard_writer.add_summary(summary, i * BATCH_SIZE + batch_id)

                batch_id += 1

            # remainder
            last_batch_size = x_train.shape[0] - next_k
            if last_batch_size > 0:
                k = next_k

                summary, o, c = s.run([merged, objective, cost],
                                      feed_dict={x_placeholder: x_train[k:k + last_batch_size],
                                                 y_placeholder: y_train_one_hot[k:k + last_batch_size]})

                print("Epoch: %d.  Batch: %d Cost:%f, Batch size: %d" % (i, batch_id, c, last_batch_size))
                tensorboard_writer.add_summary(summary, i * BATCH_SIZE + batch_id)

        log.info("Training completed.")

        weight_path = saver.save(s, str(Path(WEIGHT_DIR) / Path("model.ckpt")))
        log.info("Saved model in: %s" % weight_path)

        y_hat_test_one_hot = s.run(y_hat_softmax, feed_dict={x_placeholder: x_test})

        total_size = y_hat_test_one_hot.shape[0]
        y_hat_test_one_hot_int = np.argmax(y_hat_test_one_hot, axis=1)  # to int from one-hot vector

        matched_indices = (y_hat_test_one_hot_int == y_test)
        matched_count = y_test[matched_indices].shape[0]
        log.info(
            "Matched: %d out of Total: %d (%f percent)" % (matched_count, total_size, matched_count * 100 / total_size))


def main():
    """Defines an application's main functionality"""
    example()


if __name__ == "__main__":
    main()
